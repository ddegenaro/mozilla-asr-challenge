{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec559340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.lang_maps import HR_MAP \n",
    "from utils.task_vectors import TaskVector\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "models_dir = \"output_whisper-tiny\"\n",
    "ALL_LANGS = list(set(HR_MAP.keys()).union(set(\"_\".join(v) for v in HR_MAP.values())))\n",
    "TVs = {}\n",
    "for lang in ALL_LANGS:\n",
    "    if lang != \"\":\n",
    "        TVs[lang] = TaskVector(\n",
    "            pretrained_model=WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\"),\n",
    "            finetuned_model=WhisperForConditionalGeneration.from_pretrained(f\"{models_dir}/{lang}/final\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np \n",
    "import torch\n",
    "model = \"results/whisper-tiny\"\n",
    "rows = []\n",
    "summary_df = pd.read_csv(f\"{model}/summary.csv\")\n",
    "lang_hr_gains = {}\n",
    "for result in os.listdir(f\"{model}/hyperparameters\"):\n",
    "    with open(f\"{model}/hyperparameters/\" + result, \"r\") as f:\n",
    "        hyps = json.load(f)\n",
    "        f.close()\n",
    "    if len(hyps) > 0:\n",
    "        lang_name = result.split(\".\")[0]\n",
    "        lang_hr_gains[lang_name] = {}\n",
    "        best_score = min(hyps.values())\n",
    "        best_lambda = min(hyps, key=hyps.get)\n",
    "        score_0 = hyps[\"0.0\"]\n",
    "        lang_hr_gains[lang_name][\"lambda\"] = best_lambda\n",
    "        lang_hr_gains[lang_name][\"hr_delta\"] = abs(score_0 - best_score)\n",
    "        language_tv = TVs[lang_name]\n",
    "        hr_tv = TVs[\"_\".join(HR_MAP[lang_name])]\n",
    "        cossim = cosine_similarity(language_tv.tv_to_vector().reshape(1, -1), hr_tv.tv_to_vector().reshape(1, -1))[0][0]\n",
    "        # Calculate the element-wise difference\n",
    "        difference = [language_tv.vector[k] - hr_tv.vector[k] for k in language_tv.vector.keys()] \n",
    "        # Square each element of the difference matrix\n",
    "        squared_difference = [np.square(d.flatten()) for d in difference]\n",
    "        # Calculate the mean of all elements in the squared_difference matrix\n",
    "        mse = np.mean(torch.cat(squared_difference).numpy())\n",
    "        layer_wise_mse = [np.mean(l.numpy()) for l in squared_difference]\n",
    "        lang_hr_gains[lang_name][\"cosine_sim\"] = cossim\n",
    "        lang_hr_gains[lang_name][\"mse\"] = mse\n",
    "        lang_hr_gains[lang_name][\"layer_wise_mse\"] = layer_wise_mse\n",
    "        lang_hr_gains[lang_name][\"wer\"] = best_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44ca9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(lang_hr_gains).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('layer_wise_mse', axis=1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1befd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lang_hr_gains[\"kbd\"][\"layer_wise_mse\"]), len(lang_hr_gains[\"ukv\"][\"layer_wise_mse\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3a3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting all lines at once\n",
    "def smooth(scalars, weight):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "        \n",
    "    return smoothed\n",
    "mse_graph = [(lang, item[\"layer_wise_mse\"]) for lang, item in lang_hr_gains.items()]\n",
    "xs = range(len(mse_graph[0][1]))\n",
    "ys = np.array([smooth(v[1], 0.9) for v in mse_graph]).T\n",
    "labels = [v[0] for v in mse_graph]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(xs, ys, label=labels)\n",
    "\n",
    "# Adding labels and legend (you would need to manually create labels here if desired)\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('MSE')\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_title('MSE for target languages and their HR counterparts at each layer')\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.5), ncol=5) \n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785624d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np \n",
    "import torch\n",
    "model = \"results/whisper-tiny\"\n",
    "rows = []\n",
    "summary_df = pd.read_csv(f\"{model}/summary.csv\")\n",
    "lang_hr_gains = {}\n",
    "for result in os.listdir(f\"{model}/hyperparameters\"):\n",
    "    with open(f\"{model}/hyperparameters/\" + result, \"r\") as f:\n",
    "        hyps = json.load(f)\n",
    "        f.close()\n",
    "    if len(hyps) > 0:\n",
    "        lang_name = result.split(\".\")[0]\n",
    "        lang_hr_gains[lang_name] = {}\n",
    "        best_score = min(hyps.values())\n",
    "        best_lambda = min(hyps, key=hyps.get)\n",
    "        score_0 = hyps[\"0.0\"]\n",
    "        lang_hr_gains[lang_name][\"lambda\"] = best_lambda\n",
    "        lang_hr_gains[lang_name][\"hr_delta\"] = abs(score_0 - best_score)\n",
    "        language_tv = TVs[lang_name]\n",
    "        hr_tv = TVs[\"_\".join(HR_MAP[lang_name])]\n",
    "        # Calculate the element-wise difference\n",
    "        lr_layerwise, layer_strs = language_tv.tv_to_layer_wise()\n",
    "        hr_layerwise, _ = hr_tv.tv_to_layer_wise()\n",
    "        cossim_layerwise = [cosine_similarity(lr_layerwise[i].reshape(1, -1), hr_layerwise[i].reshape(1, -1))[0][0] for i in range(len(lr_layerwise))]\n",
    "        difference = [np.array(lr_layerwise[i]) - np.array(hr_layerwise[i]) for i in range(len(lr_layerwise))]\n",
    "        # Square each element of the difference matrix\n",
    "        squared_difference = [np.square(d) for d in difference]\n",
    "        # Calculate the mean of all elements in the squared_difference matrix\n",
    "        layer_wise_mse = [np.mean(l) for l in squared_difference]\n",
    "        lang_hr_gains[lang_name][\"cosine_sim\"] = np.mean(cossim_layerwise)\n",
    "        lang_hr_gains[lang_name][\"mse\"] = np.mean(layer_wise_mse)\n",
    "        lang_hr_gains[lang_name][\"layer_wise_mse\"] = layer_wise_mse\n",
    "        lang_hr_gains[lang_name][\"layer_wise_cossim\"] = cossim_layerwise\n",
    "\n",
    "        lang_hr_gains[lang_name][\"wer\"] = best_score\n",
    "df = pd.DataFrame(lang_hr_gains).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e166a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df\n",
    "new_cols_df = df_2['layer_wise_mse'].apply(pd.Series).round(2)\n",
    "\n",
    "new_cols_df.columns = [f'mse_{i+1}' for i in range(new_cols_df.shape[1])]\n",
    "df_2 = pd.concat([df_2.drop('layer_wise_mse', axis=1), new_cols_df], axis=1)\n",
    "\n",
    "new_cols_df = df_2['layer_wise_cossim'].apply(pd.Series).round(2)\n",
    "\n",
    "# Optionally, rename the new columns for clarity\n",
    "new_cols_df.columns = [f'cossim_{i+1}' for i in range(new_cols_df.shape[1])]\n",
    "df_2 = pd.concat([df_2.drop('layer_wise_cossim', axis=1), new_cols_df], axis=1)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cossim = np.array(df_2.cosine_sim)\n",
    "delta = np.array(df_2.hr_delta)\n",
    "model = LinearRegression()\n",
    "model.fit(delta.reshape(-1,1), cossim)\n",
    "pred = model.predict(delta.reshape(-1,1))\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(cossim, pred)\n",
    "spearman = spearmanr(cossim, delta)\n",
    "print(\"cosine_similarity\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(\"spearman\", spearman)\n",
    "\n",
    "cossim = np.array(df_2.mse)\n",
    "delta = np.array(df_2.hr_delta)\n",
    "model = LinearRegression()\n",
    "model.fit(delta.reshape(-1,1), cossim)\n",
    "pred = model.predict(delta.reshape(-1,1))\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(cossim, pred)\n",
    "spearman = spearmanr(cossim, delta)\n",
    "print(\"mse\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(\"spearman\", spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lang_hr_gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting all lines at once\n",
    "def smooth(scalars, weight):  # Weight between 0 and 1\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed = list()\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "        \n",
    "    return smoothed\n",
    "mse_graph = [(lang, item[\"layer_wise_cossim\"]) for lang, item in lang_hr_gains.items()]\n",
    "xs = range(len(mse_graph[0][1]))\n",
    "ys = np.array([smooth(v[1], 0.9) for v in mse_graph]).T\n",
    "ys = np.array([v[1]for v in mse_graph]).T\n",
    "\n",
    "labels = [v[0] for v in mse_graph]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(xs, ys, label=labels)\n",
    "\n",
    "# Adding labels and legend (you would need to manually create labels here if desired)\n",
    "ax.set_xlabel('Layer')\n",
    "ax.set_ylabel('Cosine Similarity')\n",
    "# ax.set_yscale(\"log\")\n",
    "ax.set_title('Cosine Similarity for target languages and their HR counterparts at each layer')\n",
    "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.5), ncol=5) \n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b921000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = \"results/whisper-tiny\"\n",
    "rows = []\n",
    "summary_df = pd.read_csv(f\"{model}/summary.csv\")\n",
    "token_freq_df = pd.read_csv(\"token_frequency/measures.tsv\", delimiter=\"\\t\")\n",
    "lang_hr_gains = {}\n",
    "for result in os.listdir(f\"{model}/hyperparameters\"):\n",
    "    with open(f\"{model}/hyperparameters/\" + result, \"r\") as f:\n",
    "        hyps = json.load(f)\n",
    "        f.close()\n",
    "    if len(hyps) > 0:\n",
    "        lang_name = result.split(\".\")[0]\n",
    "        lang_hr_gains[lang_name] = {}\n",
    "        best_score = hyps[min(hyps, key=hyps.get)]#summary_df.loc[summary_df['language'] == lang_name][\"wer\"]\n",
    "        best_lambda = min(hyps, key=hyps.get)\n",
    "        score_0 = hyps[\"0.0\"]\n",
    "        lang_hr_gains[lang_name][\"lambda\"] = float(best_lambda)\n",
    "        lang_hr_gains[lang_name][\"hr_delta\"] = float(abs(score_0 - best_score))\n",
    "        lang_hr_gains[lang_name][\"wer\"] = score_0\n",
    "        # language_tv = TVs[lang_name]\n",
    "        # hr_tv = TVs[\"_\".join(HR_MAP[lang_name])]\n",
    "        # hr_tv = TVs[\"_\".join(HR_MAP[lang_name])]\n",
    "        # cossim = cosine_similarity(language_tv.tv_to_vector().reshape(1, -1), hr_tv.tv_to_vector().reshape(1, -1))[0][0]\n",
    "        # lang_hr_gains[lang_name][\"tv_cossim\"] = cossim\n",
    "df = pd.DataFrame(lang_hr_gains).T\n",
    "df.rename_axis(\"lang\", inplace=True)\n",
    "df = df.reset_index()\n",
    "merged_df =pd.merge(df, token_freq_df,on=\"lang\")\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a30730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "import seaborn\n",
    "cossim = np.array(merged_df.cosine)\n",
    "delta = np.array(merged_df.hr_delta)\n",
    "wer = np.array(merged_df.wer)\n",
    "model = LinearRegression()\n",
    "model.fit(delta.reshape(-1,1), cossim)\n",
    "pred = model.predict(delta.reshape(-1,1))\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(cossim, pred)\n",
    "spearman = spearmanr(cossim, delta)\n",
    "pearson = pearsonr(cossim, delta)\n",
    "print(\"cosine_similarity predictor for delta\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(\"spearman\", spearman)\n",
    "print(\"pearson\", pearson)\n",
    "\n",
    "lamb = np.array(merged_df[\"lambda\"])\n",
    "model = LinearRegression()\n",
    "model.fit(lamb.reshape(-1,1), cossim)\n",
    "pred = model.predict(lamb.reshape(-1,1))\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(cossim, pred)\n",
    "spearman = spearmanr(cossim, lamb)\n",
    "pearson = pearsonr(cossim, lamb)\n",
    "print(\"cosine similarity predictor for lambda\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(\"spearman\", spearman)\n",
    "print(\"pearson\", pearson)\n",
    "\n",
    "wer = np.array(merged_df[\"wer\"])\n",
    "model = LinearRegression()\n",
    "model.fit(wer.reshape(-1,1), cossim)\n",
    "pred = model.predict(wer.reshape(-1,1))\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(cossim, pred)\n",
    "spearman = spearmanr(cossim, wer)\n",
    "pearson = pearsonr(cossim, wer)\n",
    "print(\"cosine similarity predictor for wer\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(\"spearman\", spearman)\n",
    "print(\"pearson\", pearson)\n",
    "\n",
    "\n",
    "seaborn.regplot(data=merged_df, x=\"cosine\", y=\"lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f50c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.regplot(data=merged_df, x=\"cosine\", y=\"hr_delta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86657244",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_cossim = np.array(merged_df[\"tv_cossim\"])\n",
    "cossim = np.array(merged_df.cosine)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(tv_cossim.reshape(-1,1), cossim)\n",
    "pred = model.predict(tv_cossim.reshape(-1,1))\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(cossim, pred)\n",
    "spearman = spearmanr(cossim, tv_cossim)\n",
    "print(\"TV cosine similarity predictor for token cossim\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(\"spearman\", spearman)\n",
    "\n",
    "seaborn.regplot(data=merged_df, x=\"tv_cossim\", y=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = \"results/whisper-large-v3\"\n",
    "rows = []\n",
    "summary_df = pd.read_csv(f\"{model}/summary.csv\")\n",
    "token_freq_df = pd.read_csv(\"token_frequency/measures.tsv\", delimiter=\"\\t\")\n",
    "lang_hr_gains = {}\n",
    "for result in os.listdir(f\"{model}/hyperparameters\"):\n",
    "    with open(f\"{model}/hyperparameters/\" + result, \"r\") as f:\n",
    "        hyps = json.load(f)\n",
    "        f.close()\n",
    "    if len(hyps) > 0:\n",
    "        lang_name = result.split(\".\")[0]\n",
    "        lang_hr_gains[lang_name] = {}\n",
    "        best_score = hyps[min(hyps, key=hyps.get)]#summary_df.loc[summary_df['language'] == lang_name][\"wer\"]\n",
    "        best_lambda = min(hyps, key=hyps.get)\n",
    "        score_0 = hyps[\"0.0\"]\n",
    "        lang_hr_gains[lang_name][\"lambda\"] = float(best_lambda)\n",
    "        lang_hr_gains[lang_name][\"hr_delta\"] = float(abs(score_0 - best_score))\n",
    "        lang_hr_gains[lang_name][\"wer\"] = score_0\n",
    "        # language_tv = TVs[lang_name]\n",
    "        # hr_tv = TVs[\"_\".join(HR_MAP[lang_name])]\n",
    "        # hr_tv = TVs[\"_\".join(HR_MAP[lang_name])]\n",
    "        # cossim = cosine_similarity(language_tv.tv_to_vector().reshape(1, -1), hr_tv.tv_to_vector().reshape(1, -1))[0][0]\n",
    "        # lang_hr_gains[lang_name][\"tv_cossim\"] = cossim\n",
    "df = pd.DataFrame(lang_hr_gains).T\n",
    "df.rename_axis(\"lang\", inplace=True)\n",
    "df = df.reset_index()\n",
    "merged_df =pd.merge(df, token_freq_df,on=\"lang\")\n",
    "merged_df\n",
    "wer = np.array(merged_df[\"wer\"])\n",
    "hr_delta = np.array(merged_df[\"hr_delta\"])\n",
    "model = LinearRegression()\n",
    "model.fit(hr_delta.reshape(-1,1), wer)\n",
    "pred = model.predict(hr_delta.reshape(-1,1))\n",
    "# Calculate R-squared\n",
    "r2 = r2_score(wer, pred)\n",
    "spearman = spearmanr(wer, hr_delta)\n",
    "pearson = pearsonr(wer, hr_delta)\n",
    "print(\"wer predictor for delta\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "print(\"spearman\", spearman)\n",
    "print(\"pearson\", pearson)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
