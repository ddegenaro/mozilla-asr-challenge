{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, BitsAndBytesConfig\n",
    "import torch\n",
    "from utils.clean_transcript import clean\n",
    "from peft import PeftModel\n",
    "import librosa\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99723ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # available GPU\n",
    "lang = 'bew' # which language to see\n",
    "num_examples = 5 # how many sentences to transcribe/view/play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483451d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, data, processor, proxy_lang):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_dtype = next(model.parameters()).dtype\n",
    "    model.to(device).eval()\n",
    "    forced_decoder_ids = processor.get_decoder_prompt_ids(language=proxy_lang, task=\"transcribe\")\n",
    "    predictions = []\n",
    "    filepaths = []\n",
    "    with torch.no_grad():\n",
    "        for filepath in tqdm(data):      \n",
    "            audio = librosa.load(filepath, offset=0, duration=30, mono=True, sr=16_000)[0]\n",
    "            inputs = processor(audio=[audio], sampling_rate=16_000, return_tensors='pt')\n",
    "            input_features = inputs.input_features.to(model.device)\n",
    "            input_features = input_features.to(dtype=input_dtype)      \n",
    "            \n",
    "           # Generate output token IDs\n",
    "            predicted_ids = model.generate(\n",
    "                input_features,\n",
    "                forced_decoder_ids=forced_decoder_ids,\n",
    "                max_new_tokens=200\n",
    "            )\n",
    "            transcriptions = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "            predictions += transcriptions\n",
    "            filepaths.append(filepath)\n",
    "    model.to(\"cpu\")\n",
    "    return predictions, filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7710999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config, model_dir, lang):\n",
    "    if config['lora']:  \n",
    "        # quantize\n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.float16\n",
    "        )\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(\n",
    "            config[\"whisper_model\"],\n",
    "            quantization_config=bnb_config\n",
    "        )\n",
    "        model = PeftModel.from_pretrained(model, f\"{model_dir}/{lang}\")        \n",
    "        model.print_trainable_parameters()\n",
    "    else:\n",
    "        model = WhisperForConditionalGeneration.from_pretrained(f\"{model_dir}/{lang}\")\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d3fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b15b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_paths = f\"/cs-data-01/drd92/mozilla-asr-challenge/mcv-sps-st-09-2025/sps-corpus-1.0-2025-09-05-{lang}/audios/*\"\n",
    "model_dir = \"results/whisper-large-v3/final_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_lang = config[\"proxy_langs\"][lang]\n",
    "processor = WhisperProcessor.from_pretrained(\n",
    "    config[\"whisper_model\"],\n",
    "    language=proxy_lang,\n",
    "    task=\"transcribe\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc1e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = glob.glob(audio_paths)[:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf76772",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(config, model_dir, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, filepaths = generate(model, data, processor, proxy_lang)\n",
    "predictions = [clean(p) for p in predictions]\n",
    "rows = []\n",
    "for i, p in enumerate(predictions):\n",
    "    rows.append([filepaths[i].split(\"/\")[-1], p])\n",
    "lang_df = pd.DataFrame(rows, columns=[\"audio_file\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f279fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_transcripts_df = pd.read_csv(\n",
    "    f\"/cs-data-01/drd92/mozilla-asr-challenge/mcv-sps-st-09-2025/sps-corpus-1.0-2025-09-05-{lang}/ss-corpus-{lang}.tsv\",\n",
    "    sep = '\\t'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed4b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, datum in enumerate(data):\n",
    "    display(Audio(datum))\n",
    "    print('pred:', lang_df.loc[i]['sentence'].strip())\n",
    "    print('gold:', gold_transcripts_df[gold_transcripts_df['audio_file'] == datum.split(os.path.sep)[-1]]['transcription'].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
